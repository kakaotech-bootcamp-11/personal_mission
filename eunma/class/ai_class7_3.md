# 1주차 'data' 강의

## 목차

1. 공지사항
2. 데이터 전처리개요
3. 데이터 수집 후 전처리 과정
4. 데이터 타입별 전처리 방법
5. 데이터 정제
6. 데이터 변환
7. 데이터 통합
8. Advanced 기법
9. 데이터 전처리 최적화
10. 실습과제

## 데이터 전처리 개요

- 원시 데이터를 분석 및 모델링에 적합하게 변환하는 과정
- 데이터의 정제, 변환, 통합 등을 포함
- 데이터 품질을 높여 신뢰성 있는 분석을 가능하게 함.

### 중요성

- 데이터 품질 향상
- 모델 성능 최적화
- 분석의 신뢰성 향상
- 데이터 활용의 효율성 향상

### 주요 단계

* 데이터 정제
- 결측값  처리
- 이상값 탐지 및 수정
- 중복 데이터 제거

* 데이터 변환
- 데이터 스케일링
- 데이터 인코딩

* 데이터 통합 및 변형
- 데이터 병합
- 데이터 집계 및 변형

## 전처리 과정

* 데이터 수집에서 전처리로의 연결
- 데이터 수집(정제가 필요)

* Y?
- 데이터는 활용을 목적으로 수집계획을 짠 경우는 거의 없음
- 선 수집 후 활용고려

* 수집된 데이터의 초기 확인 및 분석
- 데이터 불러오기
- 기본정보확인(데이터 구조, 크기, 타입)
- 결측치 및 이상치 처리

## 데이터 정제 -결측치

### 결측치의 종류

* MCAR (Missing Completely at Random)
- 데이터가 완전 무작위로 누락
- ex)설문조사에서 무작위로 질문을 건너뜀

* MAR (Missing at Random)
- 데이터 누락이 다른 관측 가능한 변수와 관련된 경우
- ex) 나이가 많은 응답자들이 소득정보를 제공하지 않음

* MNAR (Missing Not at Random)
- 데이터 누락이 자체 변수와 관련된 경우
- ex) 높은 소득을 가진 사람이 소득  정보를 제공하지 않음

### 결측값의 원인

- 데이터 입력 오류
- 응답자의 미응답
- 데이터 처리 과정의 문제

## 데이터 정제 - 이상치
- 데이터 분포에서 벗어난 극잔적인 값
- 통계적 분석과 모델 성능에 영향을 줄 수 있음

* 이상치의 원인
- 데이터 입력 오류
- 데이터 수집 문제
- 이질적 데이터 : 서로 다른 특성을 가진 그룹의 혼합, 드문 이벤트
- 자연적변동성
- 특이한 상황/조건

## 데이터 변환

### 스케일링
- 데이터의 범위를 임의로 조정해주는 과정

### 표준화(Standardization)
- 데이터의 평균을0, 표준편차를 1로 변환하여 데이터 분포를 표준정규분포로 만듬

### 정규화(Normalization)
- 데이터를 특정 범위로 변환하는 과정/regularization과는 다름

### 데이터변환의 이유
- 다양한 특성의 단위차이를 없애고, 동일한 스케일로 조정하여 모델학습에 도움
- 데이터를 일정한 범위로 조정하여 계산의 안정성과 속도 향상

## 데이터 변환 - 데이터인코딩

### 레이블 인코딩
- 범주형 데이터를 숫자로 변환하는 기법
- 각 범주를 고유한 정수로 매핑
- 수치형 데이터로 변환하여 모델 학습에 사용
- 범주 간 순서가 없는 경우 잘못된 관계를 학습할 수 있음
![alt text](image-1.png)

### 원-핫 인코딩
- 범주형 데이터를 이진 벡터로 변환
- 각 범주를 이진 벡터의 고유한 위치에 1로 표시
- 범주간 순서가 없는 데이터를 처리할 때 유용
- 모든 범주를 독립된 변수로 변환하여 모델 학습에 사용
- 많은 범주가 있는 경우, 고차원 데이터로 변환되어 메모리 사용량이 증가
![alt text](image-2.png)

## 데이터 변환 - 날짜 및 시간 데이터

### 형식 변환
- 문자열 형식의 날짜 데이터를 datetime 형식으로 변환
- 날짜 연산 및 비교를 쉽게 수행할 수 있도록 하기 위해 진행

### 추출
- 날짜 객체에서 특정 정보(연도, 월, 일)를 추출
- 날짜 데이터에서 특정 정보를 추출하여 분석에 활용하기 위해 진행

## 데이터 통합 및 변형

### 데이터 합치기
- 여러 데이터를 하나로 결합하는 과정
- 공통된 키 또는 인덱스를 사용하여 데이터 간의 데이터를 결합
- 더 풍부한 인사이트를 도출하기 위해 사용
ex) 고객 정보 데이터와 거래 내역 데이터를 결합하여 고객행동 분석

### 데이터 집계
- 데이터의 특정 열을 기준으로 합계, 평균 등의 요약 통계를 계산하는 과정
- 그룹별로 데이터를 요약하여 더 높은 수준의 인사이트 제공
- 데이터의 전반적인 경향을 파악하고, 주요 지표를 요약하여 분석의 효율성 향상
ex_월별 매출 데이터에서 각 월의 총 매출을 계산

### 데이터 그룹화
- 특정 열을 기준으로 데이터를 그룹화하여 집계하는 과정
- 그룹별로 데이터 집계를 수행하여 상세한 분석 가능
- 특정 그룹별로 데이터를 분석하여 세부적인 인사이트 제공

### 데이터의 변형(재구조화)
- 데이터 프레임의 형태를 변경하는 다양한 기법
- 데이터를 요약하거나분석 목적에 맞게 재구성
- 분석의 편의성을 높이고, 특정 분석 목표에 맞는 데이터 구조를 만들기 위해
ex_ 긴 형식의 데이터를 넓은 형식으로 변환

### 데이터 피벗
- 데이터 프레임의 행과 열을 변환하여 데이터를 요약하는 과정
- 특정 열을 인덱스로 사용하고, 다른 열을 새로운 열로 변환
- 데이터의 특정 측면을 강조하고, 요약 통계를 쉽게 확인하기 위해
ex_ 월별 제품 판매 데이터를 피벗하여 각 제품의 월별 판매량을 열로 변환

## 데이터 전처리 Advanced

### 파생 변수 생성
- 기존 데이터에서 새로운 변수를 생성하는 과정
- 기존 변수 간의 상호작용, 계산 또는 변환을 통해 새로운 정보를 추출
- 데이터의 정보량을 증가시켜 분석 및 모델링 성능을 향상
* 날짜 데이터에서 연도, 월, 일, 요일 등을 추출하여 분석의 깊이를 더함
* 텍스트 데이터에서 텍스트 길이, 단어 수 등을 파생변수로 생성
* 키, 몸무게를 이용한 BMI데이터(몸무게/(키/100)^2)

### 데이터 샘플링
- 전체 데이터셋에서 일부 데이터를 선택하여 분석이나 모델링에 사용하는 과정
- 모집단의 특성을 대표하는 샘플을 추출
- 분석의 신속성, 대용량 데이터 처리 시간과 비용을 절감
- 랜덤 샘플링 층화 샘플링

### 차원 축소 기법
- 고차원 데이터를 저차원으로 변환하여 데이터의 복잡성을 줄이는 과정
- 데이터의 변동성을 최대한 보존하면서 주요 특성을 추출
- 데이터의 시각화와 이해를 용이하게 하고, 모델의 과적합을 방지하며 계산 효율성을 향상
- PCA, t-SNE

## 데이터 전처리 회적화

### 전처리 작업의 자동화
- 반복적이고 일관된 전처리 작업을 자동화하여 효율성을 높이는 과정
- 스크립트 및 파이프라인을 사용하여 전처리 작업을 자동으로 실행
- 수동 작업의 오류를 줄이고, 작업 시간을 단축하며, 일관성을 유지

### 파이프라인 구축
- 일련의 전처리 단계를 순차적으로 자동으로 실행하는 파이프라인을 구축
- 각 단계별로 전처리 작업을 정의하고, 이를 파이프라인으로 연결
- 전처리 작업의 일관성과 재현성을 보장
- 실제 코드상의 파이프라인, 의미/구조상의 파이프라인
![alt text](image-3.png)

### 대용량 데이터 처리
- 대용량 데이터를 효율적으로 처리하기 위한 전략과 기법
- 분산 처리, 병렬 처리, 메모리 관리 등의 기법을 사용하여 데이터 처리
- 데이터 양이 클수록 처리 시간과 자원소모가 증가하므로 효율적인 처리가 필요

* 분산처리
- 데이터를 여러 노드에 분산하여 동시에 처리
- Hadoop, Spark 등의 분산 처리 프레임 워크
* 병렬처리
- 데이터를 여러 프로세스에서 동시에 처리
- multiprocessing, Dask 등의 병렬 처리 라이브러리를 사용

* 메모리 관리
- 메모리 사용을 최적화하여 대용량 데이터를 효율적으로 처리

* 효율성 향상
- 최적화된 알고리즘, 코딩 스타일 개선

* 적절한 데이터 구조 사용
- pandas, Numpy 등의 라이브러리 적절히 활용